{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "\n",
    "df1 = pd.read_csv('../datasets/peoples.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Country</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Pet</th>\n",
       "      <th>Qualification</th>\n",
       "      <th>Experience</th>\n",
       "      <th>WorkHoursPerMonth</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>210</td>\n",
       "      <td>William Lopez</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>83351.0</td>\n",
       "      <td>Cat</td>\n",
       "      <td>PhD</td>\n",
       "      <td>12.0</td>\n",
       "      <td>140.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>210</td>\n",
       "      <td>William Lopez</td>\n",
       "      <td>(941)372-2105x0132</td>\n",
       "      <td>Japan</td>\n",
       "      <td>83351.0</td>\n",
       "      <td>Cat</td>\n",
       "      <td>PhD</td>\n",
       "      <td>12.0</td>\n",
       "      <td>140.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID           Name  ... WorkHoursPerMonth Address\n",
       "210  210  William Lopez  ...             140.4     NaN\n",
       "268  210  William Lopez  ...             140.4     NaN\n",
       "\n",
       "[2 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2\n",
    "\n",
    "df2 = pd.read_csv('../datasets/peoples.csv', index_col='ID')\n",
    "\n",
    "# df2.loc[210]\n",
    "df1[df1['ID'] == 210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3\n",
    "\n",
    "df3 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Name', 'Address', 'Phone'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[5], line 6\u001b[0m\n    df4 = df4.drop(columns=cols_to_drop)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\env_mlf\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m in \u001b[0;35mdrop\u001b[0m\n    return super().drop(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\env_mlf\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m in \u001b[0;35mdrop\u001b[0m\n    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\.conda\\envs\\env_mlf\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m in \u001b[0;35m_drop_axis\u001b[0m\n    new_axis = axis.drop(labels, errors=errors)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\.conda\\envs\\env_mlf\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[1;36m in \u001b[1;35mdrop\u001b[1;36m\n\u001b[1;33m    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\u001b[1;36m\n",
      "\u001b[1;31mKeyError\u001b[0m\u001b[1;31m:\u001b[0m \"['Name', 'Address', 'Phone'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "\n",
    "df4 = df2.copy()\n",
    "cols_to_drop = ['Name', 'Address', 'Phone']\n",
    "df4 = df4.drop(cols_to_drop, axis=1)\n",
    "df4 = df4.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5\n",
    "\n",
    "nan_mask = df4.isnull().any(axis=1)\n",
    "\n",
    "df5 = df4[nan_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6\n",
    "\n",
    "df6 = df4.drop(index=3)\n",
    "df6 = df4[~nan_mask]\n",
    "df6 = df4.dropna()\n",
    "# df_ff = df2[nan_mask]\n",
    "# df_ff = df2[cols_to_drop]\n",
    "# df_ff = df2.loc[nan_mask, cols_to_drop]\n",
    "# %%\n",
    "# step 7\n",
    "\n",
    "test_df = pd.DataFrame({'one': [1, 2, 3], \n",
    "                        'two': ['a', 'b', 'c']\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df.iloc[0, 1] = 8\n",
    "new_df.loc[0, 'two'] = 88\n",
    "new_df['two'][0] = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 8\n",
    "\n",
    "duplicates_mask = df6.duplicated()\n",
    "\n",
    "df7 = df6[~duplicates_mask]\n",
    "#df7 = df6.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 9\n",
    "sns.heatmap(df7.corr(numeric_only=True), cmap='coolwarm', annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 10\n",
    "df7.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 11\n",
    "\n",
    "# df7.groupby('Country')['Salary'].mean()\n",
    "\n",
    "# df7.groupby('Pet')['Salary'].mean()\n",
    "\n",
    "# df7.groupby('Qualification')['Salary'].mean()\n",
    "\n",
    "# df7.groupby(by=['Country', 'Qualification'])['Salary'].mean()\n",
    "# df7.groupby(by=['Country', 'Qualification'])['Salary'].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 12\n",
    "\n",
    "df7['Country'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 13\n",
    "\n",
    "df8 = df7.drop(['Country', 'Pet', 'Qualification'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step hist\n",
    "\n",
    "m = df8.melt()\n",
    "\n",
    "g = sns.FacetGrid(m,\n",
    "                  col='variable',\n",
    "                  col_wrap=3,\n",
    "                  sharex=False,\n",
    "                  sharey=False)\n",
    "\n",
    "g.map(sns.histplot, 'value')\n",
    "\n",
    "g.set_titles(col_template='{col_name}')\n",
    "\n",
    "g.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 14\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 15\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                            df8.drop('Salary', axis=1),\n",
    "                                            df8['Salary'],\n",
    "                                            test_size=0.2,\n",
    "                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 16\n",
    "\n",
    "scaler = StandardScaler().set_output(transform='pandas').fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "scaler_trn = StandardScaler().set_output(transform='pandas').fit(X_train)\n",
    "scaler_all = StandardScaler().set_output(transform='pandas').fit(df8.drop('Salary', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 17\n",
    "\n",
    "model = LinearRegression().fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 18\n",
    "\n",
    "r_sq = model.score(X_test_scaled, y_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "print(f'R2: {r_sq:.2f} | MAE: {mae:.2f} | MAPE: {mape:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "\n",
    "california_housing = fetch_california_housing(as_frame=True)\n",
    "\n",
    "df_data = california_housing.data\n",
    "df_data1 = california_housing['data']\n",
    "\n",
    "df_target = california_housing.target\n",
    "\n",
    "df_frame = california_housing.frame\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
